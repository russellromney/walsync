mod config;
mod dashboard;
mod ltx;
mod retention;
mod s3;
mod sync;
mod wal;

use anyhow::{anyhow, Result};
use clap::{Parser, Subcommand};
use config::{Config, ResolvedDbConfig, RetentionConfig, SyncConfig};
use std::path::PathBuf;
use std::time::Duration;
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

#[derive(Parser)]
#[command(name = "walsync")]
#[command(about = "Lightweight SQLite WAL sync to S3/Tigris")]
struct Cli {
    /// Config file path (checks ./walsync.toml if not specified)
    #[arg(long, global = true)]
    config: Option<PathBuf>,

    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Watch SQLite databases and sync WAL changes to S3
    Watch {
        /// Database files to watch (can be omitted if config file specifies databases)
        databases: Vec<PathBuf>,

        /// S3 bucket (e.g., "s3://my-bucket/prefix")
        #[arg(short, long)]
        bucket: Option<String>,

        /// Snapshot interval in seconds
        #[arg(long)]
        snapshot_interval: Option<u64>,

        /// S3 endpoint URL (for Tigris/MinIO/etc)
        #[arg(long, env = "AWS_ENDPOINT_URL_S3")]
        endpoint: Option<String>,

        /// Take snapshot after N WAL frames (0 = disabled)
        #[arg(long)]
        max_changes: Option<u64>,

        /// Maximum seconds between snapshots when changes detected
        #[arg(long)]
        max_interval: Option<u64>,

        /// Take snapshot after N seconds of no WAL activity (0 = disabled)
        #[arg(long)]
        on_idle: Option<u64>,

        /// Take snapshot immediately on watch start
        #[arg(long)]
        on_startup: Option<bool>,

        /// Run compaction after each snapshot
        #[arg(long)]
        compact_after_snapshot: bool,

        /// Compaction interval in seconds (0 = disabled)
        #[arg(long)]
        compact_interval: Option<u64>,

        /// Number of hourly snapshots to retain
        #[arg(long)]
        retain_hourly: Option<usize>,

        /// Number of daily snapshots to retain
        #[arg(long)]
        retain_daily: Option<usize>,

        /// Number of weekly snapshots to retain
        #[arg(long)]
        retain_weekly: Option<usize>,

        /// Number of monthly snapshots to retain
        #[arg(long)]
        retain_monthly: Option<usize>,

        /// Metrics server port (default: 16767, disable with --no-metrics)
        #[arg(long, default_value = "16767")]
        metrics_port: u16,

        /// Disable metrics server
        #[arg(long)]
        no_metrics: bool,
    },

    /// Restore a database from S3
    Restore {
        /// Database name (as registered in S3)
        name: String,

        /// Output path for restored database
        #[arg(short, long)]
        output: PathBuf,

        /// S3 bucket
        #[arg(short, long)]
        bucket: String,

        /// S3 endpoint URL
        #[arg(long, env = "AWS_ENDPOINT_URL_S3")]
        endpoint: Option<String>,

        /// Restore to specific point in time (ISO 8601)
        #[arg(long)]
        point_in_time: Option<String>,
    },

    /// List databases in S3 bucket
    List {
        /// S3 bucket
        #[arg(short, long)]
        bucket: String,

        /// S3 endpoint URL
        #[arg(long, env = "AWS_ENDPOINT_URL_S3")]
        endpoint: Option<String>,
    },

    /// Take an immediate snapshot
    Snapshot {
        /// Database file
        database: PathBuf,

        /// S3 bucket
        #[arg(short, long)]
        bucket: String,

        /// S3 endpoint URL
        #[arg(long, env = "AWS_ENDPOINT_URL_S3")]
        endpoint: Option<String>,
    },

    /// Compact old snapshots using retention policy (GFS rotation)
    Compact {
        /// Database name (as registered in S3)
        name: String,

        /// S3 bucket
        #[arg(short, long)]
        bucket: String,

        /// S3 endpoint URL
        #[arg(long, env = "AWS_ENDPOINT_URL_S3")]
        endpoint: Option<String>,

        /// Number of hourly snapshots to keep (default: 24)
        #[arg(long, default_value = "24")]
        hourly: usize,

        /// Number of daily snapshots to keep (default: 7)
        #[arg(long, default_value = "7")]
        daily: usize,

        /// Number of weekly snapshots to keep (default: 12)
        #[arg(long, default_value = "12")]
        weekly: usize,

        /// Number of monthly snapshots to keep (default: 12)
        #[arg(long, default_value = "12")]
        monthly: usize,

        /// Actually delete files (default: dry-run only)
        #[arg(long)]
        force: bool,
    },

    /// Run as a read replica, polling S3 for changes
    Replicate {
        /// Source S3 location (e.g., "s3://bucket/mydb")
        source: String,

        /// Local database path for the replica
        #[arg(long)]
        local: PathBuf,

        /// Poll interval (e.g., "5s", "1m", "30s")
        #[arg(long, default_value = "5s")]
        interval: String,

        /// S3 endpoint URL
        #[arg(long, env = "AWS_ENDPOINT_URL_S3")]
        endpoint: Option<String>,
    },

    /// Explain what the current configuration will do (dry-run preview)
    Explain,

    /// Verify integrity of LTX files in S3
    Verify {
        /// Database name (as registered in S3)
        name: String,

        /// S3 bucket
        #[arg(short, long)]
        bucket: String,

        /// S3 endpoint URL
        #[arg(long, env = "AWS_ENDPOINT_URL_S3")]
        endpoint: Option<String>,

        /// Fix issues by removing orphaned manifest entries
        #[arg(long)]
        fix: bool,
    },
}

/// CLI arguments for Watch command
struct WatchArgs {
    databases: Vec<PathBuf>,
    bucket: Option<String>,
    snapshot_interval: Option<u64>,
    endpoint: Option<String>,
    max_changes: Option<u64>,
    max_interval: Option<u64>,
    on_idle: Option<u64>,
    on_startup: Option<bool>,
    compact_after_snapshot: bool,
    compact_interval: Option<u64>,
    retain_hourly: Option<usize>,
    retain_daily: Option<usize>,
    retain_weekly: Option<usize>,
    retain_monthly: Option<usize>,
    metrics_port: u16,
    no_metrics: bool,
}

/// Resolve watch configuration by merging config file with CLI args
fn resolve_watch_config(
    config: &Option<Config>,
    cli: &WatchArgs,
) -> Result<(Vec<ResolvedDbConfig>, String, Option<String>, SyncConfig, RetentionConfig)> {
    match config {
        Some(cfg) => {
            // Start with config file values, CLI overrides
            let bucket = cli
                .bucket
                .clone()
                .or(cfg.s3.bucket.clone())
                .ok_or_else(|| anyhow!("bucket required (via --bucket or config file)"))?;

            let endpoint = cli.endpoint.clone().or(cfg.s3.endpoint.clone());

            // If CLI specifies databases, use those; otherwise use config
            let resolved_dbs = if !cli.databases.is_empty() {
                // CLI databases - use global config settings with CLI overrides
                let sync = merge_cli_sync_overrides(&cfg.sync, cli);
                let retention = merge_cli_retention_overrides(&cfg.retention, cli);

                cli.databases
                    .iter()
                    .map(|p| ResolvedDbConfig {
                        path: p.clone(),
                        prefix: p
                            .file_stem()
                            .and_then(|s| s.to_str())
                            .unwrap_or("db")
                            .to_string(),
                        sync: sync.clone(),
                        retention: retention.clone(),
                    })
                    .collect()
            } else {
                // Use databases from config file
                let mut dbs = cfg.resolve_databases()?;
                if dbs.is_empty() {
                    return Err(anyhow!(
                        "No databases specified (provide paths or configure in config file)"
                    ));
                }

                // Apply CLI overrides to each database's config
                for db in &mut dbs {
                    db.sync = merge_cli_sync_overrides(&db.sync, cli);
                    db.retention = merge_cli_retention_overrides(&db.retention, cli);
                }
                dbs
            };

            // For global sync/retention, merge CLI overrides with config
            let sync = merge_cli_sync_overrides(&cfg.sync, cli);
            let retention = merge_cli_retention_overrides(&cfg.retention, cli);

            Ok((resolved_dbs, bucket, endpoint, sync, retention))
        }
        None => {
            // No config file - require CLI args
            let bucket = cli
                .bucket
                .clone()
                .ok_or_else(|| anyhow!("--bucket is required when no config file is present"))?;

            if cli.databases.is_empty() {
                return Err(anyhow!(
                    "At least one database path required when no config file is present"
                ));
            }

            // Build config from CLI with defaults
            let sync = SyncConfig {
                snapshot_interval: cli.snapshot_interval.unwrap_or(3600),
                max_changes: cli.max_changes.unwrap_or(0),
                max_interval: cli.max_interval.unwrap_or(0),
                on_idle: cli.on_idle.unwrap_or(0),
                on_startup: cli.on_startup.unwrap_or(true),
                compact_after_snapshot: cli.compact_after_snapshot,
                compact_interval: cli.compact_interval.unwrap_or(0),
            };

            let retention = RetentionConfig {
                hourly: cli.retain_hourly.unwrap_or(24),
                daily: cli.retain_daily.unwrap_or(7),
                weekly: cli.retain_weekly.unwrap_or(12),
                monthly: cli.retain_monthly.unwrap_or(12),
            };

            let resolved_dbs = cli
                .databases
                .iter()
                .map(|p| ResolvedDbConfig {
                    path: p.clone(),
                    prefix: p
                        .file_stem()
                        .and_then(|s| s.to_str())
                        .unwrap_or("db")
                        .to_string(),
                    sync: sync.clone(),
                    retention: retention.clone(),
                })
                .collect();

            Ok((
                resolved_dbs,
                bucket,
                cli.endpoint.clone(),
                sync,
                retention,
            ))
        }
    }
}

/// Merge CLI sync overrides with base config
fn merge_cli_sync_overrides(base: &SyncConfig, cli: &WatchArgs) -> SyncConfig {
    SyncConfig {
        snapshot_interval: cli.snapshot_interval.unwrap_or(base.snapshot_interval),
        max_changes: cli.max_changes.unwrap_or(base.max_changes),
        max_interval: cli.max_interval.unwrap_or(base.max_interval),
        on_idle: cli.on_idle.unwrap_or(base.on_idle),
        on_startup: cli.on_startup.unwrap_or(base.on_startup),
        compact_after_snapshot: cli.compact_after_snapshot || base.compact_after_snapshot,
        compact_interval: cli.compact_interval.unwrap_or(base.compact_interval),
    }
}

/// Merge CLI retention overrides with base config
fn merge_cli_retention_overrides(base: &RetentionConfig, cli: &WatchArgs) -> RetentionConfig {
    RetentionConfig {
        hourly: cli.retain_hourly.unwrap_or(base.hourly),
        daily: cli.retain_daily.unwrap_or(base.daily),
        weekly: cli.retain_weekly.unwrap_or(base.weekly),
        monthly: cli.retain_monthly.unwrap_or(base.monthly),
    }
}

/// Parse duration string like "5s", "1m", "30s", "2h"
fn parse_duration(s: &str) -> Result<Duration> {
    let s = s.trim();
    if s.is_empty() {
        return Err(anyhow!("Empty duration string"));
    }

    let (num_str, unit) = if s.ends_with("ms") {
        (&s[..s.len() - 2], "ms")
    } else if s.ends_with('s') {
        (&s[..s.len() - 1], "s")
    } else if s.ends_with('m') {
        (&s[..s.len() - 1], "m")
    } else if s.ends_with('h') {
        (&s[..s.len() - 1], "h")
    } else {
        return Err(anyhow!(
            "Invalid duration '{}'. Use format like '5s', '1m', '2h'",
            s
        ));
    };

    let num: u64 = num_str
        .parse()
        .map_err(|_| anyhow!("Invalid number in duration: {}", num_str))?;

    match unit {
        "ms" => Ok(Duration::from_millis(num)),
        "s" => Ok(Duration::from_secs(num)),
        "m" => Ok(Duration::from_secs(num * 60)),
        "h" => Ok(Duration::from_secs(num * 3600)),
        _ => unreachable!(),
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::registry()
        .with(tracing_subscriber::EnvFilter::new(
            std::env::var("RUST_LOG").unwrap_or_else(|_| "walsync=info".into()),
        ))
        .with(tracing_subscriber::fmt::layer())
        .init();

    let cli = Cli::parse();

    // Load config file (optional)
    let config = Config::load(cli.config.as_deref())?;

    match cli.command {
        Commands::Watch {
            databases,
            bucket,
            snapshot_interval,
            endpoint,
            max_changes,
            max_interval,
            on_idle,
            on_startup,
            compact_after_snapshot,
            compact_interval,
            retain_hourly,
            retain_daily,
            retain_weekly,
            retain_monthly,
            metrics_port,
            no_metrics,
        } => {
            let watch_args = WatchArgs {
                databases,
                bucket,
                snapshot_interval,
                endpoint,
                max_changes,
                max_interval,
                on_idle,
                on_startup,
                compact_after_snapshot,
                compact_interval,
                retain_hourly,
                retain_daily,
                retain_weekly,
                retain_monthly,
                metrics_port,
                no_metrics,
            };

            let (resolved_dbs, bucket, endpoint, sync_config, retention_config) =
                resolve_watch_config(&config, &watch_args)?;

            let compact_policy =
                if sync_config.compact_after_snapshot || sync_config.compact_interval > 0 {
                    Some(retention::RetentionPolicy::new(
                        retention_config.hourly,
                        retention_config.daily,
                        retention_config.weekly,
                        retention_config.monthly,
                    ))
                } else {
                    None
                };

            sync::watch_with_config(
                resolved_dbs,
                &bucket,
                endpoint.as_deref(),
                sync_config,
                compact_policy,
                watch_args.metrics_port,
                watch_args.no_metrics,
            )
            .await?;
        }
        Commands::Restore {
            name,
            output,
            bucket,
            endpoint,
            point_in_time,
        } => {
            sync::restore(&name, &output, &bucket, endpoint.as_deref(), point_in_time.as_deref()).await?;
        }
        Commands::List { bucket, endpoint } => {
            sync::list(&bucket, endpoint.as_deref()).await?;
        }
        Commands::Snapshot {
            database,
            bucket,
            endpoint,
        } => {
            sync::snapshot(&database, &bucket, endpoint.as_deref()).await?;
        }
        Commands::Compact {
            name,
            bucket,
            endpoint,
            hourly,
            daily,
            weekly,
            monthly,
            force,
        } => {
            let policy = retention::RetentionPolicy::new(hourly, daily, weekly, monthly);
            sync::compact(&name, &bucket, endpoint.as_deref(), &policy, force).await?;
        }

        Commands::Replicate {
            source,
            local,
            interval,
            endpoint,
        } => {
            let duration = parse_duration(&interval)?;
            sync::replicate(&source, &local, duration, endpoint.as_deref()).await?;
        }

        Commands::Explain => {
            sync::explain(&config)?;
        }

        Commands::Verify {
            name,
            bucket,
            endpoint,
            fix,
        } => {
            sync::verify(&name, &bucket, endpoint.as_deref(), fix).await?;
        }
    }

    Ok(())
}
